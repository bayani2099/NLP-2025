{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75006fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (3.16.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp39-cp39-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.10-cp39-cp39-win_amd64.whl (441 kB)\n",
      "Using cached multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.3 MB 1.0 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 0.8/25.3 MB 1.1 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 1.0/25.3 MB 1.3 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.3/25.3 MB 1.4 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 1.6/25.3 MB 1.3 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.8/25.3 MB 1.3 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 2.4/25.3 MB 1.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 2.6/25.3 MB 1.3 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 1.3 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 1.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 1.4 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 3.7/25.3 MB 1.3 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 4.2/25.3 MB 1.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 4.5/25.3 MB 1.3 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 4.7/25.3 MB 1.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 5.0/25.3 MB 1.4 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 5.5/25.3 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 5.8/25.3 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 6.0/25.3 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 6.3/25.3 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 6.3/25.3 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 1.3 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 1.3 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 1.3 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 7.6/25.3 MB 1.4 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 7.9/25.3 MB 1.3 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 8.1/25.3 MB 1.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 8.7/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 8.9/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 9.2/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 9.4/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 9.7/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 10.0/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 10.7/25.3 MB 1.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 10.7/25.3 MB 1.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 10.7/25.3 MB 1.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.5/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.5/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.8/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 12.3/25.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 12.6/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.8/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 13.1/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.4/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.4/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.6/25.3 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.9/25.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 15.2/25.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.5/25.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 16.0/25.3 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.8/25.3 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 17.0/25.3 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 17.6/25.3 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.9/25.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 19.4/25.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 19.9/25.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 20.2/25.3 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 20.7/25.3 MB 1.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.0/25.3 MB 1.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.5/25.3 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.3 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.3 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.6/25.3 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.9/25.3 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 24.1/25.3 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 1.4 MB/s eta 0:00:00\n",
      "Using cached xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 async-timeout-5.0.1 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-18.1.0 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\Arash\\anaconda3\\envs\\whisper-env\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd258ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052686c5",
   "metadata": {},
   "source": [
    "## Importing Required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7d5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e6c01",
   "metadata": {},
   "source": [
    "As our dataset is already preprocessed and splitted into training, test and development test by the split that was given to us already in the initial dataset after loading the datasets again we need to prepare them for the RoBERTA Model in a format that is acceptable for this model which can be found in the corresponding huggingFace page.\n",
    "\n",
    "Link to RoBERTA model documentation is provided below:\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/model_doc/roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de1d65",
   "metadata": {},
   "source": [
    "Because RoBERta and other similar pre-trained models are trained on general datasets and are not specialized for specific task like in our case classification of text to sexist and no-sexist we need to fine-tune the model based on our data and labels although it can be used already but the results and accuracy of the model might not be as good as it should be. we are going to compare the results of both original and fine-tuned models.\n",
    "\n",
    "But to describe why fine-tuning is needed in more details.\n",
    "Fine-tuning involves training the last few layers (and optionally all layers) of the model on your labeled data. The goal is to optimize the pre-trained weights for your task while retaining the knowledge learned during pre-training.\n",
    "\n",
    "1. It will allow the model to learn task specific patterns and adapt to our specific domain.\n",
    "2. The pre-trained model doesn't know about our labels in this condition fine-tuning will align the model's output to our specific purposes.\n",
    "3. Fine-tuning can imporve the performance of the model.\n",
    "\n",
    "- Steps of fine-tuning are as follows:\n",
    "\n",
    "1. Pre-processing the data (which we have already done)\n",
    "2. Adapting the data to our model for binary classification\n",
    "3. Adding classification head on top of RoBERTa for binary prediction\n",
    "4. Training the model using DF_train\n",
    "5. Use the fine-tuned model for predciting on test set(DF_test)\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "Steps for Fine-tuning in Your Task\n",
    "Pre-process the data: You've already preprocessed and loaded the dataset. Tokenize and prepare it for the RoBERTa model.\n",
    "Adapt the model for binary classification:\n",
    "Add a classification head (a linear layer) on top of RoBERTa for outputting binary predictions.\n",
    "Train the model:\n",
    "Use your training data (DF_train) for model training.\n",
    "Use your dev data (DF_dev) to monitor performance during training and prevent overfitting.\n",
    "Evaluate:\n",
    "Use metrics like accuracy, precision, recall, and F1 score to evaluate the fine-tuned model on the validation set (DF_dev).\n",
    "Predict:\n",
    "Use the fine-tuned model to predict labels for your test data (DF_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464d5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "DF_train=pd.read_csv('../data/preprocessed/DF_train.csv')\n",
    "DF_dev=pd.read_csv('../data/preprocessed/DF_dev.csv')\n",
    "DF_test=pd.read_csv('../data/preprocessed/DF_test.csv')\n",
    "Actual_labels=pd.read_csv('../data/preprocessed/Actual_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1ff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining datasets into format acceptable by HuggingFace:\n",
    "train_dataset = Dataset.from_pandas(DF_train[['text', 'label_sexist']])\n",
    "dev_dataset = Dataset.from_pandas(DF_dev[['text', 'label_sexist']])\n",
    "test_dataset = Dataset.from_pandas(DF_test[['text']])  # Test doesn't need labels for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1a1cd",
   "metadata": {},
   "source": [
    "After loading and making the datasets ready for the model, we need to tokenize the data which will be done using tokenizer already included in the transformer library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b25dd",
   "metadata": {},
   "source": [
    "### Loading the tokenizer and tokenizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feb44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafdeab54e3645659d55386f4cb759e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbd61af59724f70a72a7fbca7ba6955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664c24f473a24c5195211d1aa8a319e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "dev_dataset = dev_dataset.map(tokenize_data, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed18fc8",
   "metadata": {},
   "source": [
    "### Formating data for Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df61085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label_sexist\", \"labels\")\n",
    "dev_dataset = dev_dataset.rename_column(\"label_sexist\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "dev_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb271d",
   "metadata": {},
   "source": [
    "### Loading the pre-trained Roberta model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537a16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437308c1",
   "metadata": {},
   "source": [
    "### Setting up training parameters and arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822202c",
   "metadata": {},
   "source": [
    "We are going to use exactly the same parameters and arguments that were used for training RoBERTA model as they should already be the optimized ones. Parameters are copied from huggingFace documentation page which was mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce79b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arash\\anaconda3\\envs\\whisper-env\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13ea42",
   "metadata": {},
   "source": [
    "### Defining Metrics for fine-tuning the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca5e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849873cd",
   "metadata": {},
   "source": [
    "### Fine-Tuning and training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1c7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 10:36:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.314841</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.685206</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.633745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.342734</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.728435</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.699588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2625, training_loss=0.2861032879466102, metrics={'train_runtime': 38222.8101, 'train_samples_per_second': 1.099, 'train_steps_per_second': 0.069, 'total_flos': 2762666081280000.0, 'train_loss': 0.2861032879466102, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc375a7",
   "metadata": {},
   "source": [
    "### Saving the fine-tuned model for future usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3be81cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_roberta\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../fine_tuned_roberta\"\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830defd",
   "metadata": {},
   "source": [
    "### Evaluating the fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efca3abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40099582076072693, 'eval_accuracy': 0.8785, 'eval_f1': 0.7367280606717227, 'eval_precision': 0.7780320366132724, 'eval_recall': 0.6995884773662552, 'eval_runtime': 528.0448, 'eval_samples_per_second': 3.788, 'eval_steps_per_second': 0.237, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a38ac8",
   "metadata": {},
   "source": [
    "### Testing the model on our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf7d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  rewire_id  \\\n",
      "0    sexism2022_english-845   \n",
      "1   sexism2022_english-6629   \n",
      "2  sexism2022_english-17573   \n",
      "3  sexism2022_english-10268   \n",
      "4  sexism2022_english-10735   \n",
      "\n",
      "                                                text  predictions  \n",
      "0  fuck the niggers and the jews both have a hist...            0  \n",
      "1  well then good because someone has to knock he...            1  \n",
      "2  usa texas islam muslims islamization sharialaw...            0  \n",
      "3  yes normal women want to be dominated social s...            1  \n",
      "4  she didnt have to be a bitch about it she lite...            1  \n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "test_dataset = DF_test.copy()\n",
    "test_dataset[\"predictions\"] = torch.argmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "print(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d975f002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-845</td>\n",
       "      <td>fuck the niggers and the jews both have a hist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-6629</td>\n",
       "      <td>well then good because someone has to knock he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-17573</td>\n",
       "      <td>usa texas islam muslims islamization sharialaw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-10268</td>\n",
       "      <td>yes normal women want to be dominated social s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-10735</td>\n",
       "      <td>she didnt have to be a bitch about it she lite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>sexism2022_english-2356</td>\n",
       "      <td>define blatant if youre with a girl then be wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>sexism2022_english-17641</td>\n",
       "      <td>take a look at mgtow even chads know women are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>sexism2022_english-6358</td>\n",
       "      <td>when youre known as the guy who argues that wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>sexism2022_english-8770</td>\n",
       "      <td>you shouldve asked if you could be her side piece</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "0       sexism2022_english-845   \n",
       "1      sexism2022_english-6629   \n",
       "2     sexism2022_english-17573   \n",
       "3     sexism2022_english-10268   \n",
       "4     sexism2022_english-10735   \n",
       "...                        ...   \n",
       "3995   sexism2022_english-2356   \n",
       "3996  sexism2022_english-17641   \n",
       "3997   sexism2022_english-6358   \n",
       "3998   sexism2022_english-8770   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \n",
       "0     fuck the niggers and the jews both have a hist...            0  \n",
       "1     well then good because someone has to knock he...            1  \n",
       "2     usa texas islam muslims islamization sharialaw...            0  \n",
       "3     yes normal women want to be dominated social s...            1  \n",
       "4     she didnt have to be a bitch about it she lite...            1  \n",
       "...                                                 ...          ...  \n",
       "3995  define blatant if youre with a girl then be wi...            0  \n",
       "3996  take a look at mgtow even chads know women are...            1  \n",
       "3997  when youre known as the guy who argues that wo...            0  \n",
       "3998  you shouldve asked if you could be her side piece            0  \n",
       "3999         this bith should be stoped shes the rapist            0  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cac9f3",
   "metadata": {},
   "source": [
    "### Combining predictions and actual Labels for final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83c8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8738\n",
      "Precision: 0.7476\n",
      "Recall: 0.7237\n",
      "F1 Score: 0.7355\n",
      "Predictions saved to ./predictions_with_labels.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Adding actual labels to the test dataset\n",
    "evaluation_data = DF_test.copy()\n",
    "evaluation_data[\"predictions\"] = torch.argmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "evaluation_data[\"actual_labels\"] = Actual_labels[\"label_sexist\"]\n",
    "\n",
    "# Mapping numeric labels to text labels\n",
    "label_map = {0: \"not sexist\", 1: \"sexist\"}\n",
    "evaluation_data[\"predictions_text\"] = evaluation_data[\"predictions\"].map(label_map)\n",
    "evaluation_data[\"actual_labels_text\"] = evaluation_data[\"actual_labels\"].map(label_map)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"])\n",
    "precision = precision_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "recall = recall_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "f1 = f1_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Saving the final result to and Excel file:\n",
    "output_path = \"../results/predictions_with_labels_dl.xlsx\"\n",
    "columns_to_save = [\"rewire_id\", \"text\", \"predictions_text\", \"actual_labels_text\"]\n",
    "evaluation_data[columns_to_save].to_excel(output_path, index=False)\n",
    "print(f\"Predictions saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7585b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_labels</th>\n",
       "      <th>predictions_text</th>\n",
       "      <th>actual_labels_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-845</td>\n",
       "      <td>fuck the niggers and the jews both have a hist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-6629</td>\n",
       "      <td>well then good because someone has to knock he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-17573</td>\n",
       "      <td>usa texas islam muslims islamization sharialaw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-10268</td>\n",
       "      <td>yes normal women want to be dominated social s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-10735</td>\n",
       "      <td>she didnt have to be a bitch about it she lite...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>sexism2022_english-2356</td>\n",
       "      <td>define blatant if youre with a girl then be wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>sexism2022_english-17641</td>\n",
       "      <td>take a look at mgtow even chads know women are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>sexism2022_english-6358</td>\n",
       "      <td>when youre known as the guy who argues that wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>sexism2022_english-8770</td>\n",
       "      <td>you shouldve asked if you could be her side piece</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "0       sexism2022_english-845   \n",
       "1      sexism2022_english-6629   \n",
       "2     sexism2022_english-17573   \n",
       "3     sexism2022_english-10268   \n",
       "4     sexism2022_english-10735   \n",
       "...                        ...   \n",
       "3995   sexism2022_english-2356   \n",
       "3996  sexism2022_english-17641   \n",
       "3997   sexism2022_english-6358   \n",
       "3998   sexism2022_english-8770   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \\\n",
       "0     fuck the niggers and the jews both have a hist...            0   \n",
       "1     well then good because someone has to knock he...            1   \n",
       "2     usa texas islam muslims islamization sharialaw...            0   \n",
       "3     yes normal women want to be dominated social s...            1   \n",
       "4     she didnt have to be a bitch about it she lite...            1   \n",
       "...                                                 ...          ...   \n",
       "3995  define blatant if youre with a girl then be wi...            0   \n",
       "3996  take a look at mgtow even chads know women are...            1   \n",
       "3997  when youre known as the guy who argues that wo...            0   \n",
       "3998  you shouldve asked if you could be her side piece            0   \n",
       "3999         this bith should be stoped shes the rapist            0   \n",
       "\n",
       "      actual_labels predictions_text actual_labels_text  \n",
       "0                 0       not sexist         not sexist  \n",
       "1                 1           sexist             sexist  \n",
       "2                 0       not sexist         not sexist  \n",
       "3                 1           sexist             sexist  \n",
       "4                 1           sexist             sexist  \n",
       "...             ...              ...                ...  \n",
       "3995              0       not sexist         not sexist  \n",
       "3996              1           sexist             sexist  \n",
       "3997              0       not sexist         not sexist  \n",
       "3998              0       not sexist         not sexist  \n",
       "3999              1       not sexist             sexist  \n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00925b5",
   "metadata": {},
   "source": [
    "### Analyzing the Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f5faf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_labels</th>\n",
       "      <th>predictions_text</th>\n",
       "      <th>actual_labels_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sexism2022_english-9087</td>\n",
       "      <td>i would pay to see her ass cracker nsfw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sexism2022_english-295</td>\n",
       "      <td>most men know instinctually the game but their...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sexism2022_english-13224</td>\n",
       "      <td>with interior decorating skills like yours gir...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sexism2022_english-8690</td>\n",
       "      <td>isnt it convenient that she doesnt have the vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sexism2022_english-14596</td>\n",
       "      <td>its not the same goys groping women is my come...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>sexism2022_english-12476</td>\n",
       "      <td>awalt the guy had social status so she attache...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>sexism2022_english-9520</td>\n",
       "      <td>so leading women on and using them for materia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>sexism2022_english-5262</td>\n",
       "      <td>a girl who comes up with terms like substantia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>sexism2022_english-9172</td>\n",
       "      <td>it has always seemed to me that feminists goal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "11     sexism2022_english-9087   \n",
       "23      sexism2022_english-295   \n",
       "29    sexism2022_english-13224   \n",
       "41     sexism2022_english-8690   \n",
       "48    sexism2022_english-14596   \n",
       "...                        ...   \n",
       "3964  sexism2022_english-12476   \n",
       "3968   sexism2022_english-9520   \n",
       "3971   sexism2022_english-5262   \n",
       "3976   sexism2022_english-9172   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \\\n",
       "11              i would pay to see her ass cracker nsfw            0   \n",
       "23    most men know instinctually the game but their...            1   \n",
       "29    with interior decorating skills like yours gir...            0   \n",
       "41    isnt it convenient that she doesnt have the vi...            0   \n",
       "48    its not the same goys groping women is my come...            0   \n",
       "...                                                 ...          ...   \n",
       "3964  awalt the guy had social status so she attache...            0   \n",
       "3968  so leading women on and using them for materia...            1   \n",
       "3971  a girl who comes up with terms like substantia...            1   \n",
       "3976  it has always seemed to me that feminists goal...            1   \n",
       "3999         this bith should be stoped shes the rapist            0   \n",
       "\n",
       "      actual_labels predictions_text actual_labels_text  \n",
       "11                1       not sexist             sexist  \n",
       "23                0           sexist         not sexist  \n",
       "29                1       not sexist             sexist  \n",
       "41                1       not sexist             sexist  \n",
       "48                1       not sexist             sexist  \n",
       "...             ...              ...                ...  \n",
       "3964              1       not sexist             sexist  \n",
       "3968              0           sexist         not sexist  \n",
       "3971              0           sexist         not sexist  \n",
       "3976              0           sexist         not sexist  \n",
       "3999              1       not sexist             sexist  \n",
       "\n",
       "[505 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering rows where predictions and actual_labels are not equal\n",
    "mismatched_rows = evaluation_data[evaluation_data['predictions'] != evaluation_data['actual_labels']]\n",
    "\n",
    "mismatched_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f9ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_mis = \"../results/mismatch_dl.xlsx\"\n",
    "columns = [\"rewire_id\", \"text\", \"predictions_text\", \"actual_labels_text\"]\n",
    "mismatched_rows[columns].to_excel(output_path_mis, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cce810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper-env",
   "language": "python",
   "name": "whisper-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
