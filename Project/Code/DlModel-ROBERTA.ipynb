{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052686c5",
   "metadata": {},
   "source": [
    "## Importing Required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7d5bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\asus\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e6c01",
   "metadata": {},
   "source": [
    "As our dataset is already preprocessed and splitted into training, test and development test by the split that was given to us already in the initial dataset after loading the datasets again we need to prepare them for the RoBERTA Model in a format that is acceptable for this model which can be found in the corresponding huggingFace page.\n",
    "\n",
    "Link to RoBERTA model documentation is provided below:\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/model_doc/roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de1d65",
   "metadata": {},
   "source": [
    "Because RoBERta and other similar pre-trained models are trained on general datasets and are not specialized for specific task like in our case classification of text to sexist and no-sexist we need to fine-tune the model based on our data and labels although it can be used already but the results and accuracy of the model might not be as good as it should be. we are going to compare the results of both original and fine-tuned models.\n",
    "\n",
    "But to describe why fine-tuning is needed in more details.\n",
    "Fine-tuning involves training the last few layers (and optionally all layers) of the model on your labeled data. The goal is to optimize the pre-trained weights for your task while retaining the knowledge learned during pre-training.\n",
    "\n",
    "1. It will allow the model to learn task specific patterns and adapt to our specific domain.\n",
    "2. The pre-trained model doesn't know about our labels in this condition fine-tuning will align the model's output to our specific purposes.\n",
    "3. Fine-tuning can imporve the performance of the model.\n",
    "\n",
    "- Steps of fine-tuning are as follows:\n",
    "\n",
    "1. Pre-processing the data (which we have already done)\n",
    "2. Adapting the data to our model for binary classification\n",
    "3. Adding classification head on top of RoBERTa for binary prediction\n",
    "4. Training the model using DF_train\n",
    "5. Use the fine-tuned model for predciting on test set(DF_test)\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "Steps for Fine-tuning in Your Task\n",
    "Pre-process the data: You've already preprocessed and loaded the dataset. Tokenize and prepare it for the RoBERTa model.\n",
    "Adapt the model for binary classification:\n",
    "Add a classification head (a linear layer) on top of RoBERTa for outputting binary predictions.\n",
    "Train the model:\n",
    "Use your training data (DF_train) for model training.\n",
    "Use your dev data (DF_dev) to monitor performance during training and prevent overfitting.\n",
    "Evaluate:\n",
    "Use metrics like accuracy, precision, recall, and F1 score to evaluate the fine-tuned model on the validation set (DF_dev).\n",
    "Predict:\n",
    "Use the fine-tuned model to predict labels for your test data (DF_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e6d84-39a8-4fb7-8a06-6f8ce2f2b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "DF_train=pd.read_csv('../data/preprocessed/DF_train.csv')\n",
    "DF_dev=pd.read_csv('../data/preprocessed/DF_dev.csv')\n",
    "DF_test=pd.read_csv('../data/preprocessed/DF_test.csv')\n",
    "Actual_labels=pd.read_csv('../data/preprocessed/Actual_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a1ff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining datasets into format acceptable by HuggingFace:\n",
    "train_dataset = Dataset.from_pandas(DF_train[['text', 'label_sexist']])\n",
    "dev_dataset = Dataset.from_pandas(DF_dev[['text', 'label_sexist']])\n",
    "test_dataset = Dataset.from_pandas(DF_test[['text']])  # Test doesn't need labels for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1a1cd",
   "metadata": {},
   "source": [
    "After loading and making the datasets ready for the model, we need to tokenize the data which will be done using tokenizer already included in the transformer library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b25dd",
   "metadata": {},
   "source": [
    "### Loading the tokenizer and tokenizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8feb44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14000/14000 [00:04<00:00, 3276.16 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 2267.73 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 2237.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "dev_dataset = dev_dataset.map(tokenize_data, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed18fc8",
   "metadata": {},
   "source": [
    "### Formating data for Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7df61085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label_sexist\", \"labels\")\n",
    "dev_dataset = dev_dataset.rename_column(\"label_sexist\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "dev_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb271d",
   "metadata": {},
   "source": [
    "### Loading the pre-trained Roberta model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "537a16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437308c1",
   "metadata": {},
   "source": [
    "### Setting up training parameters and arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822202c",
   "metadata": {},
   "source": [
    "We are going to use exactly the same parameters and arguments that were used for training RoBERTA model as they should already be the optimized ones. Parameters are copied from huggingFace documentation page which was mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ce79b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13ea42",
   "metadata": {},
   "source": [
    "### Defining Metrics for fine-tuning the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ca5e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849873cd",
   "metadata": {},
   "source": [
    "### Fine-Tuning and training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1c7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 10:36:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.314841</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.685206</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.633745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.342734</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.728435</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.699588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2625, training_loss=0.2861032879466102, metrics={'train_runtime': 38222.8101, 'train_samples_per_second': 1.099, 'train_steps_per_second': 0.069, 'total_flos': 2762666081280000.0, 'train_loss': 0.2861032879466102, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc375a7",
   "metadata": {},
   "source": [
    "### Saving the fine-tuned model for future usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3be81cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_roberta\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../fine_tuned_roberta\"\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830defd",
   "metadata": {},
   "source": [
    "### Evaluating the fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efca3abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40099582076072693, 'eval_accuracy': 0.8785, 'eval_f1': 0.7367280606717227, 'eval_precision': 0.7780320366132724, 'eval_recall': 0.6995884773662552, 'eval_runtime': 528.0448, 'eval_samples_per_second': 3.788, 'eval_steps_per_second': 0.237, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a38ac8",
   "metadata": {},
   "source": [
    "### Testing the model on our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf7d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  rewire_id  \\\n",
      "0    sexism2022_english-845   \n",
      "1   sexism2022_english-6629   \n",
      "2  sexism2022_english-17573   \n",
      "3  sexism2022_english-10268   \n",
      "4  sexism2022_english-10735   \n",
      "\n",
      "                                                text  predictions  \n",
      "0  fuck the niggers and the jews both have a hist...            0  \n",
      "1  well then good because someone has to knock he...            1  \n",
      "2  usa texas islam muslims islamization sharialaw...            0  \n",
      "3  yes normal women want to be dominated social s...            1  \n",
      "4  she didnt have to be a bitch about it she lite...            1  \n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "test_dataset = DF_test.copy()\n",
    "test_dataset[\"predictions\"] = torch.argmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "print(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d975f002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-845</td>\n",
       "      <td>fuck the niggers and the jews both have a hist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-6629</td>\n",
       "      <td>well then good because someone has to knock he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-17573</td>\n",
       "      <td>usa texas islam muslims islamization sharialaw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-10268</td>\n",
       "      <td>yes normal women want to be dominated social s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-10735</td>\n",
       "      <td>she didnt have to be a bitch about it she lite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>sexism2022_english-2356</td>\n",
       "      <td>define blatant if youre with a girl then be wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>sexism2022_english-17641</td>\n",
       "      <td>take a look at mgtow even chads know women are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>sexism2022_english-6358</td>\n",
       "      <td>when youre known as the guy who argues that wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>sexism2022_english-8770</td>\n",
       "      <td>you shouldve asked if you could be her side piece</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "0       sexism2022_english-845   \n",
       "1      sexism2022_english-6629   \n",
       "2     sexism2022_english-17573   \n",
       "3     sexism2022_english-10268   \n",
       "4     sexism2022_english-10735   \n",
       "...                        ...   \n",
       "3995   sexism2022_english-2356   \n",
       "3996  sexism2022_english-17641   \n",
       "3997   sexism2022_english-6358   \n",
       "3998   sexism2022_english-8770   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \n",
       "0     fuck the niggers and the jews both have a hist...            0  \n",
       "1     well then good because someone has to knock he...            1  \n",
       "2     usa texas islam muslims islamization sharialaw...            0  \n",
       "3     yes normal women want to be dominated social s...            1  \n",
       "4     she didnt have to be a bitch about it she lite...            1  \n",
       "...                                                 ...          ...  \n",
       "3995  define blatant if youre with a girl then be wi...            0  \n",
       "3996  take a look at mgtow even chads know women are...            1  \n",
       "3997  when youre known as the guy who argues that wo...            0  \n",
       "3998  you shouldve asked if you could be her side piece            0  \n",
       "3999         this bith should be stoped shes the rapist            0  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cac9f3",
   "metadata": {},
   "source": [
    "### Combining predictions and actual Labels for final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e83c8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8738\n",
      "Precision: 0.7476\n",
      "Recall: 0.7237\n",
      "F1 Score: 0.7355\n",
      "Predictions saved to ../results/predictions_with_labels_dl.xlsx\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3030\n",
      "           1       0.75      0.72      0.74       970\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.83      0.82      0.83      4000\n",
      "weighted avg       0.87      0.87      0.87      4000\n",
      "\n",
      "Misclassification Rate: 0.1262\n",
      "Balanced Accuracy: 0.8227\n"
     ]
    }
   ],
   "source": [
    "# Adding actual labels to the test dataset\n",
    "evaluation_data = DF_test.copy()\n",
    "evaluation_data[\"predictions\"] = torch.argmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "evaluation_data[\"actual_labels\"] = Actual_labels[\"label_sexist\"]\n",
    "\n",
    "# Mapping numeric labels to text labels\n",
    "label_map = {0: \"not sexist\", 1: \"sexist\"}\n",
    "evaluation_data[\"predictions_text\"] = evaluation_data[\"predictions\"].map(label_map)\n",
    "evaluation_data[\"actual_labels_text\"] = evaluation_data[\"actual_labels\"].map(label_map)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"])\n",
    "precision = precision_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "recall = recall_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "f1 = f1_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"], average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Saving the final result to and Excel file:\n",
    "output_path = \"../results/predictions_with_labels_dl.xlsx\"\n",
    "columns_to_save = [\"rewire_id\", \"text\", \"predictions_text\", \"actual_labels_text\"]\n",
    "evaluation_data[columns_to_save].to_excel(output_path, index=False)\n",
    "print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "# Classification report for test set\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"]))\n",
    "\n",
    "# Calculate misclassification rate\n",
    "accuracy=classification_report(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"],output_dict=True)['accuracy']\n",
    "misclassification_rate=1-accuracy\n",
    "# Calculate balanced accuracy\n",
    "balanced_accuracy=balanced_accuracy_score(evaluation_data[\"actual_labels\"], evaluation_data[\"predictions\"])\n",
    "\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4a222-448d-4fba-bd85-7dcbf01d68b5",
   "metadata": {},
   "source": [
    "The misclassification rate tells you how often the model gets predictions wrong overall. And the balanced accuracy provides a fairer measure of the model's ability to classify when the dataset may have unequal class distributions.\n",
    "misclassification rate of 0.1262 indicates that 12.62% of predictions made by the model are incorrect.\n",
    "A balanced accuracy of 0.8227 indicates that, on average, the model correctly identifies 82.27% of the samples across all classes, adjusting for any class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7585b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_labels</th>\n",
       "      <th>predictions_text</th>\n",
       "      <th>actual_labels_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-845</td>\n",
       "      <td>fuck the niggers and the jews both have a hist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-6629</td>\n",
       "      <td>well then good because someone has to knock he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-17573</td>\n",
       "      <td>usa texas islam muslims islamization sharialaw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-10268</td>\n",
       "      <td>yes normal women want to be dominated social s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-10735</td>\n",
       "      <td>she didnt have to be a bitch about it she lite...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>sexism2022_english-2356</td>\n",
       "      <td>define blatant if youre with a girl then be wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>sexism2022_english-17641</td>\n",
       "      <td>take a look at mgtow even chads know women are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>sexism2022_english-6358</td>\n",
       "      <td>when youre known as the guy who argues that wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>sexism2022_english-8770</td>\n",
       "      <td>you shouldve asked if you could be her side piece</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "0       sexism2022_english-845   \n",
       "1      sexism2022_english-6629   \n",
       "2     sexism2022_english-17573   \n",
       "3     sexism2022_english-10268   \n",
       "4     sexism2022_english-10735   \n",
       "...                        ...   \n",
       "3995   sexism2022_english-2356   \n",
       "3996  sexism2022_english-17641   \n",
       "3997   sexism2022_english-6358   \n",
       "3998   sexism2022_english-8770   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \\\n",
       "0     fuck the niggers and the jews both have a hist...            0   \n",
       "1     well then good because someone has to knock he...            1   \n",
       "2     usa texas islam muslims islamization sharialaw...            0   \n",
       "3     yes normal women want to be dominated social s...            1   \n",
       "4     she didnt have to be a bitch about it she lite...            1   \n",
       "...                                                 ...          ...   \n",
       "3995  define blatant if youre with a girl then be wi...            0   \n",
       "3996  take a look at mgtow even chads know women are...            1   \n",
       "3997  when youre known as the guy who argues that wo...            0   \n",
       "3998  you shouldve asked if you could be her side piece            0   \n",
       "3999         this bith should be stoped shes the rapist            0   \n",
       "\n",
       "      actual_labels predictions_text actual_labels_text  \n",
       "0                 0       not sexist         not sexist  \n",
       "1                 1           sexist             sexist  \n",
       "2                 0       not sexist         not sexist  \n",
       "3                 1           sexist             sexist  \n",
       "4                 1           sexist             sexist  \n",
       "...             ...              ...                ...  \n",
       "3995              0       not sexist         not sexist  \n",
       "3996              1           sexist             sexist  \n",
       "3997              0       not sexist         not sexist  \n",
       "3998              0       not sexist         not sexist  \n",
       "3999              1       not sexist             sexist  \n",
       "\n",
       "[4000 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00925b5",
   "metadata": {},
   "source": [
    "### Analyzing the Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f5faf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_labels</th>\n",
       "      <th>predictions_text</th>\n",
       "      <th>actual_labels_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sexism2022_english-9087</td>\n",
       "      <td>i would pay to see her ass cracker nsfw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sexism2022_english-295</td>\n",
       "      <td>most men know instinctually the game but their...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sexism2022_english-13224</td>\n",
       "      <td>with interior decorating skills like yours gir...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sexism2022_english-8690</td>\n",
       "      <td>isnt it convenient that she doesnt have the vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sexism2022_english-14596</td>\n",
       "      <td>its not the same goys groping women is my come...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>sexism2022_english-12476</td>\n",
       "      <td>awalt the guy had social status so she attache...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>sexism2022_english-9520</td>\n",
       "      <td>so leading women on and using them for materia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>sexism2022_english-5262</td>\n",
       "      <td>a girl who comes up with terms like substantia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>sexism2022_english-9172</td>\n",
       "      <td>it has always seemed to me that feminists goal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bith should be stoped shes the rapist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rewire_id  \\\n",
       "11     sexism2022_english-9087   \n",
       "23      sexism2022_english-295   \n",
       "29    sexism2022_english-13224   \n",
       "41     sexism2022_english-8690   \n",
       "48    sexism2022_english-14596   \n",
       "...                        ...   \n",
       "3964  sexism2022_english-12476   \n",
       "3968   sexism2022_english-9520   \n",
       "3971   sexism2022_english-5262   \n",
       "3976   sexism2022_english-9172   \n",
       "3999   sexism2022_english-3523   \n",
       "\n",
       "                                                   text  predictions  \\\n",
       "11              i would pay to see her ass cracker nsfw            0   \n",
       "23    most men know instinctually the game but their...            1   \n",
       "29    with interior decorating skills like yours gir...            0   \n",
       "41    isnt it convenient that she doesnt have the vi...            0   \n",
       "48    its not the same goys groping women is my come...            0   \n",
       "...                                                 ...          ...   \n",
       "3964  awalt the guy had social status so she attache...            0   \n",
       "3968  so leading women on and using them for materia...            1   \n",
       "3971  a girl who comes up with terms like substantia...            1   \n",
       "3976  it has always seemed to me that feminists goal...            1   \n",
       "3999         this bith should be stoped shes the rapist            0   \n",
       "\n",
       "      actual_labels predictions_text actual_labels_text  \n",
       "11                1       not sexist             sexist  \n",
       "23                0           sexist         not sexist  \n",
       "29                1       not sexist             sexist  \n",
       "41                1       not sexist             sexist  \n",
       "48                1       not sexist             sexist  \n",
       "...             ...              ...                ...  \n",
       "3964              1       not sexist             sexist  \n",
       "3968              0           sexist         not sexist  \n",
       "3971              0           sexist         not sexist  \n",
       "3976              0           sexist         not sexist  \n",
       "3999              1       not sexist             sexist  \n",
       "\n",
       "[505 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering rows where predictions and actual_labels are not equal\n",
    "mismatched_rows = evaluation_data[evaluation_data['predictions'] != evaluation_data['actual_labels']]\n",
    "mismatched_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f9ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_mis = \"../results/mismatch_dl.xlsx\"\n",
    "columns = [\"rewire_id\", \"text\", \"predictions_text\", \"actual_labels_text\"]\n",
    "mismatched_rows[columns].to_excel(output_path_mis, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217f94a-c272-43e0-8390-43dc507a3001",
   "metadata": {},
   "source": [
    "Misspellings in the text, a lack of context, and the mislabeling of data are key factors contributing to this mismatch. For instance, the sentence *\"with interior decorating skills like yours girls will be falling all over you im falling for you a little myself\"* is classified by the model as not sexist, whereas the actual label is sexist. The absence of context or knowledge of the tone makes it challenging to determine the correct classification, and it may also highlight potential biases in the actual labels.\n",
    "Another example is the sentence *\"this bith should be stoped shes the rapist\"* which contains misspellings and lacks context. Again, the sentence is classified as not sexist by the model, despite the actual label being sexist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5db07-9d47-4489-9e0d-4658d7185212",
   "metadata": {},
   "source": [
    "## Fine tuning the Fine-tuned model (fine_tuned_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb0253b-3652-4bd6-b4c0-ef030d2cfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine_tuned_roberta=RobertaForSequenceClassification.from_pretrained(\"fine_tuned_roberta\")\n",
    "tokenizer_fine_tuned_roberta=RobertaTokenizer.from_pretrained(\"fine_tuned_roberta\")\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer_fine_tuned_roberta(examples[\"text\"],truncation=True,padding=\"max_length\",max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e9ff681-9e15-49ff-9a94-d28affed5da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 2519.89 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1825.85 examples/s]\n",
      "Map: 100%|██████████| 80/80 [00:00<00:00, 1407.30 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 870.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "DF_test=pd.read_csv('../data/preprocessed/DF_test.csv')\n",
    "DF_test=Dataset.from_pandas(DF_test[['text']])\n",
    "DF_test=DF_test.map(tokenize_data,batched=True)\n",
    "Actual_labels=pd.read_csv('../data/preprocessed/Actual_labels.csv')\n",
    "GPT_Generated_test=pd.read_csv('../data/relabeled/generatedDataset.csv')\n",
    "\n",
    "# LabelEncoding\n",
    "label_mapping={\" Sexist\":1,\" Not sexist\":0}\n",
    "# Encode using the mapping\n",
    "GPT_Actual_labels=GPT_Generated_test['label']\n",
    "GPT_Actual_labels=[label_mapping[label] for label in GPT_Actual_labels]\n",
    "GPT_Generated_test.drop('label',axis=1,inplace=True)\n",
    "GPT_Generated_test.drop('id',axis=1,inplace=True)\n",
    "GPT_Actual_labels=pd.DataFrame(GPT_Actual_labels)\n",
    "GPT_Generated_test=Dataset.from_pandas(GPT_Generated_test[['text']])\n",
    "GPT_Generated_test=GPT_Generated_test.map(tokenize_data,batched=True)\n",
    "\n",
    "DF_train_subset=pd.read_csv('../data/relabeled/DF_train_subset_Juliane.csv')\n",
    "Train,Dev=train_test_split(DF_train_subset,test_size=0.2,random_state=3)\n",
    "\n",
    "Train=Dataset.from_pandas(Train[['text', 'label_sexist']])\n",
    "Train=Train.map(tokenize_data,batched=True)\n",
    "Train=Train.rename_column(\"label_sexist\", \"labels\")\n",
    "Train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "Dev=Dataset.from_pandas(Dev[['text', 'label_sexist']])\n",
    "Dev=Dev.map(tokenize_data,batched=True)\n",
    "Dev=Dev.rename_column(\"label_sexist\", \"labels\")\n",
    "Dev.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f18cbb-3fbd-4e51-932b-d72d3e6490f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = torch.tensor(logits)  # Convert logits to a PyTorch tensor\n",
    "    predictions = torch.argmax(logits, dim=-1)  # Get predictions\n",
    "    predictions = predictions.numpy()  # Convert predictions to a NumPy array\n",
    "    # Labels are already NumPy arrays; no need for `.cpu()`\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1)\n",
    "\n",
    "trainer_fine_tuned=Trainer(\n",
    "    model=model_fine_tuned_roberta,\n",
    "    args=training_args,\n",
    "    train_dataset=Train,\n",
    "    eval_dataset=Dev,\n",
    "    tokenizer=tokenizer_fine_tuned_roberta,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86574d0d-598e-4044-ae43-e111fc66665a",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e29cb2-7359-4ea9-bc52-7bffbcd5cf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408514</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.931400</td>\n",
       "      <td>0.358112</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.931400</td>\n",
       "      <td>0.315461</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.82242325146993, metrics={'train_runtime': 117.6545, 'train_samples_per_second': 2.04, 'train_steps_per_second': 0.127, 'total_flos': 15786663321600.0, 'train_loss': 0.82242325146993, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_fine_tuned.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1468c-506a-4e47-a941-23f4fd820bee",
   "metadata": {},
   "source": [
    "### Save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27ec476-6df8-440e-bb9d-d5cac32c4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ../fine_tuned_roberta_v2\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../fine_tuned_roberta_v2\"\n",
    "trainer_fine_tuned.save_model(output_dir)\n",
    "tokenizer_fine_tuned_roberta.save_pretrained(output_dir)\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40abbb5f-482e-44ee-a428-660844430ca8",
   "metadata": {},
   "source": [
    "### evaluate & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07650aa-7fd0-40a8-8505-3d2be939a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4085139334201813, 'eval_accuracy': 0.85, 'eval_f1': 0.8, 'eval_precision': 0.6666666666666666, 'eval_recall': 1.0, 'eval_runtime': 2.3939, 'eval_samples_per_second': 8.355, 'eval_steps_per_second': 0.835, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results=trainer_fine_tuned.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "466c9f9d-a53d-4c2b-9441-e97d6d8283c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_DF_test = trainer_fine_tuned.predict(DF_test)\n",
    "predictions_GPT_Generated_test = trainer_fine_tuned.predict(GPT_Generated_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5604155-0ba1-4d4d-8b2c-eba48098edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=torch.argmax(torch.tensor(predictions_DF_test.predictions), dim=-1).numpy()\n",
    "predictions_GPT_test=torch.argmax(torch.tensor(predictions_GPT_Generated_test.predictions), dim=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16324324-0d05-4e68-894b-685174441343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8405\n",
      "Precision: 0.6343\n",
      "Recall: 0.8082\n",
      "F1 Score: 0.7108\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      3030\n",
      "           1       0.63      0.81      0.71       970\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.78      0.83      0.80      4000\n",
      "weighted avg       0.86      0.84      0.85      4000\n",
      "\n",
      "Misclassification Rate: 0.1595\n",
      "Balanced Accuracy: 0.8295\n"
     ]
    }
   ],
   "source": [
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(Actual_labels,predictions_test)\n",
    "precision = precision_score(Actual_labels,predictions_test,average=\"binary\")\n",
    "recall = recall_score(Actual_labels,predictions_test,average=\"binary\")\n",
    "f1 = f1_score(Actual_labels,predictions_test,average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Classification report for test set\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(Actual_labels,predictions_test))\n",
    "\n",
    "# Calculate misclassification rate\n",
    "accuracy=classification_report(Actual_labels,predictions_test,output_dict=True)['accuracy']\n",
    "misclassification_rate=1-accuracy\n",
    "# Calculate balanced accuracy\n",
    "balanced_accuracy=balanced_accuracy_score(Actual_labels,predictions_test)\n",
    "\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d34087-e83e-4ffa-8dec-064fbafd0369",
   "metadata": {},
   "source": [
    "These results indicate that the model has an overall accuracy of 84.05% on the original test set. It performs very well on classifying the majority class (0) with high precision and recall, but is less effective on the minority class (1), as shown by its lower precision (63.43%) and a higher recall (80.82%). The balanced accuracy of 82.95% suggests the model has a fairly good performance across both classes, though the misclassification rate is 15.95%. The F1 score of 71.08% highlights that there's room for improvement, especially in balancing precision and recall for the minority class.\n",
    "\n",
    "The major changes between the results are the overall performance and balance between classes. Before the second fine-tuning, the model had higher accuracy (87.38%) and better precision (74.76%) and recall (72.37%) for the minority class (1), but after the second fine-tuning, these metrics dropped slightly, resulting in an accuracy of 84.05%, precision of 63.43%, and recall of 80.82% for the minority class. The fine_tuned_roberta_v2 model also showed improved performance balance across classes, reflected in a higher F1 score (71.08% vs. 73.55%) for the minority class. Essentially, second fine-tuning with new relabled data subset enhanced the balance between classes at the cost of a slight overall accuracy decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ca7e7bd-6399-4147-a33b-21ab56167e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5500\n",
      "Precision: 1.0000\n",
      "Recall: 0.1000\n",
      "F1 Score: 0.1818\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        50\n",
      "           1       1.00      0.10      0.18        50\n",
      "\n",
      "    accuracy                           0.55       100\n",
      "   macro avg       0.76      0.55      0.44       100\n",
      "weighted avg       0.76      0.55      0.44       100\n",
      "\n",
      "Misclassification Rate: 0.4500\n",
      "Balanced Accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(GPT_Actual_labels,predictions_GPT_test)\n",
    "precision = precision_score(GPT_Actual_labels,predictions_GPT_test,average=\"binary\")\n",
    "recall = recall_score(GPT_Actual_labels,predictions_GPT_test,average=\"binary\")\n",
    "f1 = f1_score(GPT_Actual_labels,predictions_GPT_test,average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Classification report for test set\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(GPT_Actual_labels,predictions_GPT_test))\n",
    "\n",
    "# Calculate misclassification rate\n",
    "accuracy=classification_report(GPT_Actual_labels,predictions_GPT_test,output_dict=True)['accuracy']\n",
    "misclassification_rate=1-accuracy\n",
    "# Calculate balanced accuracy\n",
    "balanced_accuracy=balanced_accuracy_score(GPT_Actual_labels,predictions_GPT_test)\n",
    "\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528f5d8-c1d4-4a4e-a860-bb4dcea66f2c",
   "metadata": {},
   "source": [
    "The results on the test set generated by ChatGPT indicate a drastic drop in overall model performance. The accuracy is significantly lower at 55.00%, with a perfect precision of 100.00% for class 1, but an extremely low recall of 10.00%, leading to a very low F1 score of 18.18%. This suggests the model is overfitting class 1 to the point of only predicting it when absolutely certain, missing a lot of actual positives. For class 0, the model has a good recall but mediocre precision. The misclassification rate is high at 45.00%, and the balanced accuracy is at only 55.00%, indicating poor performance across both classes. This shows that the fine-tuned model does not generalize well to the ChatGPT generated test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c8dc5-e24a-4f94-8483-ea113531386d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
